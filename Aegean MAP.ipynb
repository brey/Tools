{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ipywidgets import *\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from mpl_toolkits.basemap import Basemap, shiftgrid\n",
    "import pygrib\n",
    "import glob\n",
    "import string\n",
    "from shapely.geometry import Point, mapping\n",
    "from fiona import collection\n",
    "from ipywidgets import widgets\n",
    "import copy\n",
    "import urllib\n",
    "import netCDF4\n",
    "import scipy.interpolate\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SAVEPATH='mnt/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all forecast for wind and pinpoint maximum wind time frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gribapi import *\n",
    "from redtoreg import _redtoreg\n",
    "from pygrib import gaulats\n",
    "\n",
    "def gridd(lon1,lat1,lon2,lat2,nlats):\n",
    "\n",
    "        #   lon1, lat1 = self.longitude_first_gridpoint, self.latitude_first_gridpoint\n",
    "        #   lon2, lat2 = self.longitude_last_gridpoint, self.latitude_last_gridpoint\n",
    "        #   nlats = self.points_in_y_direction\n",
    "            # ECMWF 'reduced' gaussian grid.\n",
    "            nlons = 2*nlats\n",
    "            delon = 360./nlons\n",
    "        #   lons = np.arange(lon1,lon2,delon)\n",
    "            lons = np.linspace(lon1,lon2,nlons)\n",
    "            # compute gaussian lats (north to south)\n",
    "            lats = gaulats(nlats)\n",
    "            if lat1 > lat2 :\n",
    "                lats = lats[::-1]\n",
    "          # lons = lons[::-1]\n",
    "            lons,lats = np.meshgrid(lons,lats) # make 2-d arrays\n",
    "\n",
    "            return lons,lats\n",
    "\n",
    "\n",
    "def getd(f,t):\n",
    "        gid = grib_new_from_file(f)#,headers_only = True)\n",
    "        if gid is None:\n",
    "            print 'time = {}, gid = None'.format(t)\n",
    "            sys.exit(1)\n",
    "\n",
    "        name=grib_get(gid, 'shortName')\n",
    "        mv=grib_get(gid,'missingValue')\n",
    "\n",
    "        lonfgp=grib_get(gid,'longitudeOfFirstGridPointInDegrees')\n",
    "        latfgp=grib_get(gid,'latitudeOfFirstGridPointInDegrees')\n",
    "        lonlgp=grib_get(gid,'longitudeOfLastGridPointInDegrees')\n",
    "        latlgp=grib_get(gid,'latitudeOfLastGridPointInDegrees')\n",
    "\n",
    "        if grib_get(gid,'gridType') == 'regular_gg':\n",
    "\n",
    "          Ni=grib_get(gid,'Ni')\n",
    "          Nj=grib_get(gid,'Nj')\n",
    "          lat=grib_get_array(gid,'latitudes')\n",
    "          lat=lat.reshape(Nj,Ni)\n",
    "          lat=np.flipud(lat)\n",
    "          lon=grib_get_array(gid,'longitudes')\n",
    "          lon=lon.reshape(Nj,Ni)\n",
    "\n",
    "          values=grib_get_values(gid)\n",
    "          dat=values.reshape(Nj,Ni)\n",
    "          dat=np.flipud(dat)\n",
    "\n",
    "        elif grib_get(gid,'gridType') == 'reduced_gg' :\n",
    "\n",
    "          ss=grib_get_array(gid,'pl')  # lons per lat for the reduced_gg grid\n",
    "          lon,lat = gridd(lonfgp,latfgp,lonlgp,latlgp,ss.size)\n",
    "\n",
    "          values=grib_get_values(gid)\n",
    "          ny=2*np.size(ss)\n",
    "\n",
    "          dat=_redtoreg(ny,ss,values,mv)\n",
    "          dat=np.flipud(dat)\n",
    "\n",
    "        grib_release(gid)\n",
    "\n",
    "        return name,dat,lon,lat\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function to save to geotiff file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from osgeo import gdal,gdal_array\n",
    "import osr\n",
    "\n",
    "dataTypeformat={1:np.byte,2:np.int32,3:np.int32,4:np.float32,5:np.float32,6:np.byte}\n",
    "VSType={1:'VS_BOOLEAN',2:'VS_NOMINAL',3:'VS_ORDINAL',4:'VS_SCALAR',5:'VS_DIRECTION',6:'VS_LDD'}\n",
    "\n",
    "def putmap(filename,var,geo,TYPE,nodata):\n",
    "     driver=gdal.GetDriverByName('PCRaster')\n",
    "     varw=var.astype(dataTypeformat[TYPE])\n",
    "     gtype=gdal_array.NumericTypeCodeToGDALTypeCode(varw.dtype)\n",
    "     NROWS,NCOLS = var.shape\n",
    "     VS='PCRASTER_VALUESCALE={}'.format(VSType[TYPE])\n",
    "     dst_ds=driver.Create(filename,NCOLS,NROWS,1,gtype,[VS])\n",
    "     proj=osr.SpatialReference()\n",
    "     proj.ImportFromEPSG(4326)\n",
    "     dst_ds.SetProjection(proj.ExportToWkt())\n",
    "     dst_ds.SetGeoTransform(geo)\n",
    "     dst_ds.GetRasterBand(1).WriteArray(varw)\n",
    "     dst_ds.GetRasterBand(1).SetNoDataValue(nodata)\n",
    "     dst_ds.FlushCache()\n",
    "     dst_ds=None\n",
    "     return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to create a mask for the area we want. We also include the bathymetry in order to get the max wind over sea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set PATH of the database.\n",
    "PATHbase=\"/mnt/ECMWF/grib/\"  # Local mapping location for the above network drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CreateMask(minlon=5.,maxlon=48.,minlat=28.,maxlat=45.):\n",
    "    yday=datetime.date.today()-datetime.timedelta(days=1)\n",
    "    \n",
    "    PATH=PATHbase+\"%04i/%02i/%02i/\" % (yday.year,yday.month,yday.day)\n",
    "\n",
    "    dpath=glob.glob(PATH+\"*%04i%02i%02i.%02i.tropical_cyclone.grib\" % (yday.year,yday.month,yday.day,0))\n",
    "\n",
    "    try:\n",
    "         data,lons,lats = getd(dpath[0],0) \n",
    "    except:        \n",
    "         print '{} not available'.format(dpath[0])\n",
    "         return\n",
    "      \n",
    "    w=(lats > minlat) & (lats < maxlat) # mask latitudes\n",
    "    z=(lons > minlon) & (lons < maxlon) # mask longitudes BE CAREFUL OF & AND | DEPENDING\n",
    "    d=w&z # joined mask\n",
    "\n",
    "    # get topography\n",
    "    # Read data from: http://coastwatch.pfeg.noaa.gov/erddap/griddap/usgsCeSrtm30v6.html\n",
    "    # using the netCDF output option\n",
    "    base_url='http://coastwatch.pfeg.noaa.gov/erddap/griddap/usgsCeSrtm30v6.nc?'\n",
    "    query='topo[(%f):%d:(%f)][(%f):%d:(%f)]' % (maxlat,5,minlat,minlon,5,maxlon)\n",
    "    url = base_url+query\n",
    "    # store data in NetCDF file?\n",
    "    file='usgsCeSrtm30v6.nc'\n",
    "    urllib.urlretrieve (url, file)\n",
    "\n",
    "   # open NetCDF data in\n",
    "    nc = netCDF4.Dataset(file)\n",
    "    ncv = nc.variables\n",
    "    #print ncv.keys()\n",
    "\n",
    "    lon = ncv['longitude'][:]\n",
    "    lat = ncv['latitude'][:]\n",
    "    topo = ncv['topo'][:,:]\n",
    "    # interpolate on the wind grid\n",
    "    # flip lat in order to make it increasing\n",
    "    lat=np.flipud(lat)\n",
    "    # evaluate the interpolating function \n",
    "    f=scipy.interpolate.interp2d(lon,lat,np.flipud(topo),kind='cubic') # note that we also flip topo due to the flip of lat above\n",
    "    \n",
    "    #replicate the wind grid\n",
    "    alat=lats[:,0]\n",
    "    alon=lons[0,:]\n",
    "    # mask the 1-D arrays\n",
    "    aw=(alat > minlat) & (alat < maxlat)\n",
    "    az=(alon > minlon) & (alon < maxlon)\n",
    "    wlat=alat[aw]\n",
    "    wlon=alon[az]\n",
    "    # interpolate on the new grid for the topography on the wind grid\n",
    "    itopo = f(wlon,wlat)\n",
    "    \n",
    "    # mask positive values   \n",
    "    b=itopo<0.\n",
    "    # create a mask of wind shape \n",
    "    mask=np.zeros(lats.shape,dtype=bool)\n",
    "    # modify the window mask to account only for the sea points\n",
    "    mask[d]=b.flatten()\n",
    "    #total mask on the window and over sea\n",
    "    \n",
    "    return mask\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the window of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minlat=30.\n",
    "maxlat=41.5\n",
    "minlon=18.\n",
    "maxlon=36.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/ECMWF/grib/2016/08/29/20160829.00.tropical_cyclone.grib not available in /mnt/ECMWF/grib/2016/08/29/\n"
     ]
    }
   ],
   "source": [
    "mask=CreateMask(minlon,maxlon,minlat,maxlat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scan the forecast for the maximum wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def maxv(yyyy=2016,mm=1,dd=25,hh=0,save=False):\n",
    "    hh=np.int(hh) # The variables are passed as string and needs to become integer to be used later\n",
    "    yyyy=np.int(yyyy)\n",
    "    mm=np.int(mm)\n",
    "    dd=np.int(dd)\n",
    "\n",
    "    # specify date to plot.\n",
    "    date = datetime.datetime(yyyy,mm,dd,hh)\n",
    "\n",
    "    # set PATH of the database.\n",
    "    PATHbase=\"/mnt/Tsunamiweb/grib/\"  # Local mapping location for the above network drive\n",
    "  # PATHbase=\"/mnt/ECMWF/grib/\"  # Local mapping location for the above network drive\n",
    "    PATH=PATHbase+\"%04i/%02i/%02i/\" % (yyyy,mm,dd)\n",
    "    \n",
    "    dpath=glob.glob(PATH+\"*%04i%02i%02i.%02i.tropical_cyclone.grib\" % (yyyy,mm,dd,hh))\n",
    "\n",
    "    maxvel=0.0\n",
    "    for time in range(0,49,3):\n",
    "\n",
    "       try:\n",
    "         data,lons,lats = getd(dpath[0],time) \n",
    "       except:        \n",
    "         print 'no available data in ', PATH\n",
    "         return\n",
    "    # read u,v\n",
    "       ud=np.flipud(data['10u']) # because of the flip of lats\n",
    "       vd=np.flipud(data['10v']) # because of the flip of lats\n",
    "       u=np.ma.masked_array(ud,mask=np.invert(mask)) # invert mask for setting true the window values\n",
    "       v=np.ma.masked_array(vd,mask=np.invert(mask)) # invert mask for setting true the window values\n",
    "    # \n",
    "       vel=np.sqrt(u**2+v**2)\n",
    "       if vel.max() > maxvel:\n",
    "           maxvel=max([maxvel,vel.max()])\n",
    "           timestamp=time\n",
    "\n",
    "    return maxvel, timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test\n",
    "#val,t=maxv(2016,1,25,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot the graph for the timestamp..\n",
    "\n",
    "The interactive function is below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def wmap(yyyy=2016,mm=1,dd=28,hh=12,save=False):\n",
    "    hh=np.int(hh) # The variables are passed as string and needs to become integer to be used later\n",
    "    yyyy=np.int(yyyy)\n",
    "    mm=np.int(mm)\n",
    "    dd=np.int(dd)\n",
    "    # specify date to plot.\n",
    "    date = datetime.datetime(yyyy,mm,dd,hh)\n",
    "\n",
    "    # set PATH of the database.\n",
    "    PATHbase=\"/mnt/Tsunamiweb/grib/\"  # Local mapping location for the above network drive\n",
    "  # PATHbase=\"/mnt/ECMWF/grib/\"  # Local mapping location for the above network drive\n",
    "    PATH=PATHbase+\"%04i/%02i/%02i/\" % (yyyy,mm,dd)\n",
    "\n",
    "    dpath=glob.glob(PATH+\"*%04i%02i%02i.%02i.tropical_cyclone.grib\" % (yyyy,mm,dd,hh))\n",
    "\n",
    "    # get the timestamp of the maximum air speed\n",
    "    val,tmax=maxv(yyyy,mm,dd,hh)\n",
    "    \n",
    "    # plot the map of this timestamp\n",
    "    \n",
    "    try:\n",
    "        data,lon,lat = getd(dpath[0],tmax) # for faster reading THERE ARE SOME ISSUES WITH IT\n",
    "    except:\n",
    "        print 'no available data in ', PATH\n",
    "        return\n",
    "\n",
    "    # get sea level pressure and 10-m wind data.\n",
    "  #  pd=data['msl'] # because of the flip of lats\n",
    "    ud=data['10u'] # here we should flip because of the flip of lats but it is done below manually\n",
    "    vd=data['10v'] # here we should flip because of the flip of lats but it is done below manually\n",
    "    \n",
    "    # read lats,lons\n",
    "    latitudes = lat[:,0]\n",
    "    longitudes = lon[0,:]\n",
    "    # mult slp by 0.01 to put in units of hPa\n",
    "   # slpin = 0.01*pd.squeeze()\n",
    "    uin=ud.squeeze()\n",
    "    vin=vd.squeeze()\n",
    "\n",
    "\n",
    "    # add cyclic points manually (could use addcyclic function) NOTE THAT WE ALSO FLIP.. SEE ABOVE\n",
    "#    slp= np.zeros((slpin.shape[0],slpin.shape[1]+1),np.float64)\n",
    "#    slp[:,0:-1] = slpin[::-1]; slp[:,-1] = slpin[::-1,0]\n",
    "    u= np.zeros((uin.shape[0],uin.shape[1]+1),np.float64)\n",
    "    u[:,0:-1] = uin[::-1]; u[:,-1] = uin[::-1,0]\n",
    "    v= np.zeros((vin.shape[0],vin.shape[1]+1),np.float64)\n",
    "    v[:,0:-1] = vin[::-1]; v[:,-1] = vin[::-1,0]\n",
    "\n",
    "    longitudes=np.append(longitudes,360.)\n",
    "\n",
    "    lons, lats = np.meshgrid(longitudes,latitudes)\n",
    "\n",
    "    # make orthographic basemap.\n",
    "    m = Basemap(projection='cyl',llcrnrlat=minlat,urcrnrlat=maxlat,\\\n",
    "             llcrnrlon=minlon,urcrnrlon=maxlon,resolution='c')\n",
    "    # create figure, add axes\n",
    "    fig1 = plt.figure(figsize=(8,10))\n",
    "    ax = fig1.add_axes([0.1,0.1,0.8,0.8])\n",
    "    # set desired contour levels.\n",
    "    clevs = np.arange(960,1061,5)\n",
    "\n",
    "    # compute native x,y coordinates of grid.\n",
    "    x, y = m(lons, lats)\n",
    "\n",
    "    # define parallels and meridians to draw.\n",
    "    parallels = np.arange(-90.,90,20.)\n",
    "    meridians = np.arange(0.,360.,20.)\n",
    "    # plot SLP contours.\n",
    " #   slpg,newlons = shiftgrid(180.,slp,longitudes,start=False)\n",
    " #   slpd,xx,yy = \\\n",
    " #   m.transform_scalar(slpg,newlons,latitudes,181,181,returnxy=True,masked=True)\n",
    " #   CS1 = m.contour(x,y,slp,clevs,linewidths=0.5,colors='k',animated=True)\n",
    " #   CS2 = m.contourf(x,y,slp,clevs,cmap=plt.cm.RdBu_r,animated=True)\n",
    "    # plot wind vectors on projection grid.\n",
    "    # first, shift grid so it goes from -180 to 180 (instead of 0 to 360\n",
    "    # in longitude).  Otherwise, interpolation is messed up.\n",
    "    ugrid,newlons = shiftgrid(180.,u,longitudes,start=False)\n",
    "    vgrid,newlons = shiftgrid(180.,v,longitudes,start=False)\n",
    "    \n",
    "    nn=81\n",
    "    dd=(maxlon-minlon)/nn\n",
    "    nj=np.int((maxlat-minlat)/dd)\n",
    "    ni=np.int((maxlon-minlon)/dd)\n",
    "   # print ni,nj\n",
    "    # transform vectors to projection grid.\n",
    "    uproj,vproj,xx,yy = \\\n",
    "    m.transform_vector(ugrid,vgrid,newlons,latitudes,ni,nj,returnxy=True,masked=True)\n",
    "    # now plot.\n",
    "    vel=np.sqrt(uproj**2+vproj**2)\n",
    "    \n",
    "    CS1 = m.contour(xx,yy,vel,10,linewidths=0.5,colors='k',animated=True)\n",
    "    CS2 = m.contourf(xx,yy,vel,10,cmap=plt.cm.RdBu_r,animated=True)\n",
    "\n",
    "    stepx=10\n",
    "    stepy=5\n",
    "    \n",
    "    Q = m.quiver(xx,yy,uproj,vproj,scale=700)\n",
    "    # make quiver key.\n",
    "    qk = plt.quiverkey(Q, 0.1, 0.1, 20, '20 m/s', labelpos='W')\n",
    "    # draw coastlines, parallels, meridians.\n",
    "    m.drawcoastlines(linewidth=1.5)\n",
    "    m.drawparallels(parallels)\n",
    "    m.drawmeridians(meridians)\n",
    "    # add colorbar\n",
    "    cb = m.colorbar(CS2,\"right\", size=\"5%\", pad=\"2%\")\n",
    "    cb.set_label('m/s')\n",
    "    # set plot title\n",
    "    ax.set_title('Wind Speed at '+ datetime.datetime.strftime(date+datetime.timedelta(hours=tmax), '%a %b %d  %H:%M:%S %Z %Y'))\n",
    "    \n",
    "\n",
    "    if save :\n",
    "    \n",
    "    #compute direction\n",
    "    \n",
    "     theta=(180./np.pi)*np.arctan2(uproj,vproj)\n",
    "        \n",
    "    #write to shapefile\n",
    "     loc=zip(xx.flatten(),yy.flatten(),vel.flatten(),theta.flatten())\n",
    "    \n",
    "     filename=datetime.datetime.strftime(date+datetime.timedelta(hours=tmax), '%Y%m%d%H')\n",
    "    \n",
    "     schema = { 'geometry': 'Point', 'properties': { 'vel': 'float', 'dir': 'float' } }\n",
    "        \n",
    "     with collection(SAVEPATH+'vector/'+filename+\".shp\", \"w\", \"ESRI Shapefile\", schema) as output:\n",
    "        for x,y,v,th in loc:\n",
    "            point = Point(x,y)\n",
    "            output.write({\n",
    "                'properties': {\n",
    "                    'vel': v,\n",
    "                    'dir': th\n",
    "                },\n",
    "                'geometry': mapping(point)\n",
    "            })\n",
    "    #write to geotiff\n",
    "    \n",
    "     TYPE=4     \n",
    "     geo=(xx.min(),dd,0,yy.max(),0, -dd)  \n",
    "     nodata=-9999.\n",
    "     putmap(SAVEPATH+'/raster/wind.tif',velg,geo,TYPE,nodata)\n",
    "\n",
    "     ds=datetime.datetime.strftime(date+datetime.timedelta(hours=tmax),'%a %b %d  %H:%M:%S %Z %Y')\n",
    "     np.savetxt(SAVEPATH+'/txt/TIMESTAMP.txt',['{}   {}'.format(val,ds)],fmt='%s')\n",
    "\n",
    "    fig1.savefig(SAVEPATH+'aegean_waves.png')\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return tmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test\n",
    "tmax=wmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test\n",
    "#tmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define range of file attributes\n",
    "yy=[2015,2016]\n",
    "yy=[w for w in map(str,yy )]\n",
    "mm=np.arange(1,13)\n",
    "mm=[w for w in map(str,mm )]\n",
    "dd=np.arange(1,32)\n",
    "dd=[w for w in map(str,dd )]\n",
    "hh=[0,12]\n",
    "hh=[w for w in map(str,hh )]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmax=interact_manual(wmap, yyyy=yy, mm=mm, dd=dd, hh=hh, save=widgets.Checkbox())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the waves for this timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmax.widget.result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the values of the date stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dd=tmax.widget.kwargs['dd']\n",
    "mm=tmax.widget.kwargs['mm']\n",
    "hh=tmax.widget.kwargs['hh']\n",
    "yyyy=tmax.widget.kwargs['yyyy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function for reading HNMS grib\n",
    "def readgrib(INPUT):\n",
    "    f = open(INPUT)\n",
    "\n",
    "#    for t in range(3*time):\n",
    "#        gid = grib_new_from_file(f,headers_only = True)\n",
    "\n",
    "    for l in range(1):\n",
    "        gid = grib_new_from_file(f)\n",
    "        if gid is None: break\n",
    "\n",
    "        name=grib_get(gid, 'shortName')\n",
    "\n",
    "        ni = grib_get(gid, 'Ni')\n",
    "\n",
    "        nj =  grib_get(gid, 'Nj')\n",
    "\n",
    "        lat=grib_get_array(gid,'latitudes')\n",
    "        lon=grib_get_array(gid,'longitudes')\n",
    "\n",
    "        dat=grib_get_array(gid,'values')\n",
    "\n",
    "        grib_release(gid)\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    return dat.reshape(nj,ni),lat.reshape(nj,ni),lon.reshape(nj,ni)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def map_waves(yyyy=2016,mm=2,dd=1,hh=0,time=1,save=False):\n",
    "    hh=np.int(hh) # The variables are passed as string and needs to become integer to be used later\n",
    "    yyyy=np.int(yyyy)\n",
    "    mm=np.int(mm)\n",
    "    dd=np.int(dd)\n",
    "    time=np.int(time)\n",
    "    # specify date to plot.\n",
    "    date = datetime.datetime(yyyy,mm,dd,hh)\n",
    "\n",
    "    # set PATH of the database.\n",
    "    PATHbase=\"/mnt/Tsunamiweb/grib_HNMS_WAV/\"  # Local mapping location for the above network drive\n",
    "  # PATHbase=\"/mnt/ECMWF/grib/\"  # Local mapping location for the above network drive\n",
    "    PATH=PATHbase+\"%04i/%02i/%02i/\" % (yyyy,mm,dd)\n",
    "\n",
    "    dpath=glob.glob(PATH+'*_{:04d}_{:02d}_{:02d}_{:02d}00_{:02d}h.grb'.format(yyyy,mm,dd,hh,time))\n",
    "\n",
    "    try:\n",
    "        data = pygrib.open(dpath[0])\n",
    "    #    data,lats,lons = readgrib(dpath[0])\n",
    "    # read lats,lons\n",
    "        latlons=data[1].latlons()\n",
    "    # reverse latitudes so they go from south to north.\n",
    "        lats = np.flipud(latlons[0]) # make them increasing\n",
    "        lons = latlons[1]\n",
    " #      lats=np.flipud(lats)\n",
    "    # get significant height\n",
    "        sh = data[1].data()[0]\n",
    " #      sh = np.ma.masked_equal(data,9999.)\n",
    "        shi =np.flipud(sh) # make them increasing in lat\n",
    "    except:\n",
    "        print 'no available data in ', PATH\n",
    "        return\n",
    "\n",
    "    # make orthographic basemap.\n",
    "    m = Basemap(projection='cyl',llcrnrlat=minlat,urcrnrlat=maxlat,\\\n",
    "             llcrnrlon=minlon,urcrnrlon=maxlon,resolution='h')\n",
    "    # create figure, add axes\n",
    "    fig2 = plt.figure(figsize=(8,10))\n",
    "    ax = fig2.add_axes([0.1,0.1,0.8,0.8])\n",
    "    # set desired contour levels.\n",
    "    clevs = np.arange(960,1061,5)\n",
    "\n",
    "    # compute native x,y coordinates of grid.\n",
    "    x, y = m(lons, lats)\n",
    "    # define parallels and meridians to draw.\n",
    "    parallels = np.arange(-90.,90,10.)\n",
    "    meridians = np.arange(0.,360.,10.)\n",
    "\n",
    "    # plot SLP contours.\n",
    "    CS1 = m.contour(x,y,shi,20,linewidths=0.5,colors='k',animated=True)\n",
    "    CS2 = m.contourf(x,y,shi,20,cmap=plt.cm.RdBu_r,animated=True)\n",
    "    # draw coastlines, parallels, meridians.\n",
    "    m.drawcoastlines(linewidth=1.5)\n",
    "    m.drawparallels(parallels)\n",
    "    m.drawmeridians(meridians)\n",
    "    # add colorbar\n",
    "    cb = m.colorbar(CS2,\"right\", size=\"5%\", pad=\"2%\")\n",
    "    cb.set_label('m')\n",
    "    # set plot title\n",
    "    ax.set_title('Significant height of combined wind waves and swell  \\n'+ datetime.datetime.strftime(date+datetime.timedelta(hours=time), '%a %b %d  %H:%M:%S %Z %Y'))\n",
    "\n",
    "    if save :\n",
    "    # create a small matrix for the window\n",
    "\n",
    "     latitudes = lats[:,0]\n",
    "     longitudes = lons[0,:]\n",
    "\n",
    "     wg=(latitudes > minlat) & (latitudes < maxlat) # 1-D mask latitudes\n",
    "     zg=(longitudes > minlon) & (longitudes < maxlon) # 1-D mask longitudes BE CAREFUL OF & AND | DEPENDING\n",
    "\n",
    "     i1,i2=np.argwhere(wg==True).min(),np.argwhere(wg==True).max()\n",
    "     j1,j2=np.argwhere(zg==True).min(),np.argwhere(zg==True).max()\n",
    "\n",
    "     ni,nj=np.argwhere(wg==True).size,np.argwhere(zg==True).size\n",
    "     shgc=np.zeros((ni,nj))\n",
    "\n",
    "     shgc=shi[i1:i2+1,j1:j2+1]\n",
    "     shgc=np.flipud(shgc) # flip to save to geotif\n",
    "\n",
    "    #write to geotiff\n",
    "\n",
    "     TYPE=4\n",
    "\n",
    "     geo=(longitudes[j1],data[1].jDirectionIncrementInDegrees,0,latitudes[i2],0, -data[1].iDirectionIncrementInDegrees)\n",
    "#     geo=(lons.min(),data[1].iDirectionIncrementInDegrees,0,lats.max(),0, -data[1].jDirectionIncrementInDegrees)\n",
    "     nodata=sh.fill_value\n",
    "     putmap(SAVEPATH+'raster/sws.tif',shgc,geo,TYPE,nodata)\n",
    "\n",
    "\n",
    "    fig2.savefig(SAVEPATH+'aegean_waves.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test\n",
    "#map_waves(time=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "  map_waves( yyyy=yyyy,mm=mm,dd=dd,hh=hh,time=tmax.widget.result,save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
